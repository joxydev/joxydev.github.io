# Голосовой переводчик — Demo

Обновлённый учебный демо-проект, показывающий цепочку работы с голосом в браузере: вход — распознавание (STT) → перевод (Translate) → синтез речи (TTS).
Цель — дать компактную, но расширяемую основу для изучения Web Speech API, интеграции внешних сервисов и создания удобного UX.

Где смотреть
- Файлы проекта: [voice-translator/index.html](voice-translator/index.html) и [voice-translator/app.js](voice-translator/app.js).

Ключевой функционал (обновлённый)
- Браузерное распознавание речи (`SpeechRecognition`) с `interimResults` (промежуточные результаты).
- Перевод через настраиваемый эндпойнт (по умолчанию LibreTranslate) с экспоненциальным retry.
- Воспроизведение перевода через `SpeechSynthesis` с выбором голоса и расширенными параметрами (`rate`/`pitch`/`volume`).
- Push-to-talk режим, авто-стоп по паузе, отображение `confidence` и промежуточных транскриптов.
- История распознаваний/переводов в `localStorage` с поиском, копированием, экспортом (JSON/TXT), восстановлением и удалением.
- Загрузка аудио-файлов и отправка на STT-эндпойнт (при наличии) с поддержкой сегментов и генерацией SRT.
- Логи действий и ошибок (`localStorage`) с просмотром и экспортом.

Технологии
- Vanilla HTML/CSS/JavaScript (ES6+)
- Web Speech API: `SpeechRecognition` и `SpeechSynthesis`
- Fetch API для HTTP-запросов
- LocalStorage для истории, настроек и логов

Установка и локальный запуск
1. Запустите простой статический сервер из корня репозитория (любой — `live-server`, `python -m http.server`, и т.д.).

```bash
# пример с Python 3
python -m http.server 8000
# или (если установлен) live-server
npx live-server ./voice-translator --port=8001
```

2. Откройте в браузере `http://127.0.0.1:8000/voice-translator/` (или порт, который вы выбрали).

Важно о разрешениях и CORS
- Web Speech API требует HTTPS в большинстве браузеров (но работает на `localhost`). Убедитесь, что сайт загружен по HTTPS или используется `localhost` при разработке.
- Публичные экземпляры переводчиков и STT могут блокировать запросы по CORS. В таком случае укажите в интерфейсе собственный эндпойнт (поля "API-эндпойнт" и "STT эндпойнт") или используйте сервер-прокси/обёртку.

Конфигурация эндпойнтов
- Перевод: укажите URL в поле `API-эндпойнт` (по-умолчанию `https://libretranslate.de/translate`). Ожидается JSON-ответ с полем `translatedText`. Если сервис возвращает `detectedLanguage` — приложение покажет его при `source=auto`.
- STT (аудио): укажите URL в поле `STT эндпойнт`. Ожидаемые форматы ответов:
  - простой блок `{ "text": "..." }` — будет конвертирован в один сегмент;
  - или массив/объект `segments` где каждый сегмент содержит `{ start: <sec>, end: <sec>, text: "..." }`.

Как пользоваться (быстрая инструкция)
1. Выберите `Исходный язык` или `Auto`.
2. Нажмите `Начать запись` или используйте `Push-to-talk` (удерживайте кнопку `Нажать и говорить`).
3. Смотрите промежуточные результаты в поле `interim` и финальный текст в `Распознанный текст`.
4. Перевод появится в поле `Перевод`. Нажмите `Воспроизвести перевод` для озвучивания.

Дополнительные возможности
- Настройки TTS: `rate`, `pitch`, `volume` — сохраняются в `localStorage` и применяются к каждому воспроизведению.
- История: все распознавания/переводы сохраняются автоматически в ключ `vt_history` и доступны для поиска, копирования, скачивания и восстановления.
- Загрузка аудио: выберите файл и нажмите `Распознать и перевести` — файл отправится на указанный STT-эндпойнт, результат можно экспортировать в SRT (`Экспорт SRT`).
- Логи: события и ошибки сохраняются в `vt_logs` (localStorage) — их можно скачать для отладки.

Формат ожидаемых ответов от STT/Translate
- Translate (LibreTranslate-like): ожидается JSON с ключом `translatedText`. Дополнительно допустимы `detectedLanguage` / `detected_language` для уточнения языка.
- STT: рекомендуется возвращать `segments` с временными метками. Если возвращается просто `text`, приложение создаст один сегмент.

Где смотреть код
- Интерфейс и разметка: [voice-translator/index.html](voice-translator/index.html)
- Основная логика: [voice-translator/app.js](voice-translator/app.js)
- Стили: [voice-translator/style.css](voice-translator/style.css)

Коротко — что было реализовано по пунктам (1..7)
1) Browser / fallback: проверка возможностей, подсказки и блокировка кнопки записи при отсутствии API.
2) Auto-language: `recognition.lang` теперь использует `navigator.language`, `interimResults=true`, и показ детекции языка.
3) Interactive UX: `interim` вывод, `push-to-talk`, авто-стоп по паузе и отображение confidence.
4) Network/CORS: поле для кастомного `API-эндпойнта`, проверка эндпойнта, retry/backoff и кнопка «Повторить».
5) History & export: хранение в `localStorage`, поиск, копирование, экспорт JSON/TXT, восстановление записей.
6) Advanced TTS: `rate`, `pitch`, `volume`, авто-выбор голоса по целевому языку и play-sample.
7) Audio upload & subtitles: загрузка аудио, отправка на STT, генерация SRT и логирование ошибок.

Дальше — идеи для расширения
- Поддержка платных/высокоточных STT (Google/Whisper/Deepgram) через серверную интеграцию.
- Асинхронная очередь задач для обработки больших аудиофайлов и прогресс-бар.
- Сохранение истории на сервере, экспорт/импорт настроек пользователя.

Автор и лицензия
- Учебный проект — свободен для изучения и модификации.

Если нужно, могу сгенерировать пример серверной обёртки (Node/Python) для безопасного обращения к платным API и обхода CORS.
